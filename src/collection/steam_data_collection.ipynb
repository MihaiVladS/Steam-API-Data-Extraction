{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries needed for this proces\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import numpy\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this block creates functions that can be used to extract the data from the steam API\n",
    "##maybe we can add this block in the source file as a functions file\n",
    "\n",
    "def get_request(url, parameters=None):\n",
    "    #function to create an API request based on URL and  parameters\n",
    "    print(\"Your request is being processed.\")\n",
    "    response = requests.get(url=url, params=parameters)\n",
    "    if response:\n",
    "        return response.json()\n",
    "        \n",
    "    else:\n",
    "        print(\"Request unsuccessful, retrying in 5 seconds.\")\n",
    "        time.sleep(5)\n",
    "        return get_request(url, parameters)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "def getAppList():\n",
    "    #using the function to get all data id's which include appid and app name \n",
    "    url = \"https://api.steampowered.com/ISteamApps/GetAppList/v2/\"\n",
    "    parameters = {\"request\": all}\n",
    "    return get_request(url, parameters=parameters)\n",
    "    print(\"Your request has been processed successfully, call upon 'data_ids' to preview the full list of IDs and names of all currently available products on Steam as of \", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), \".\")\n",
    "    \n",
    "\n",
    "def getAppDetails(id):\n",
    "    #function to collect the raw data from the api per app_id\n",
    "    url = \"http://store.steampowered.com/api/appdetails/\"\n",
    "    parameters = {\"appids\": {id}}\n",
    "    raw_data = get_request(url, parameters=parameters)\n",
    "    response = raw_data[str(id)]\n",
    "    if(response['success']):\n",
    "        data_json = response[\"data\"]\n",
    "        data_json['collection_details'] = {'created_by': 'our_scraper',\n",
    "                                            'created_at': datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}\n",
    "        f = open('..\\\\..\\\\data\\\\raw_data.json','a',encoding='utf-8')\n",
    "        f.write(json.dumps(data_json)+'\\n')\n",
    "        f.close()\n",
    "        return data_json\n",
    "    return \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your request is being processed.\n",
      "Creating a list of all IDs currently available on Steam\n",
      "List created sucessfully, the total number of IDs available on Steam is: 138583 .\n"
     ]
    }
   ],
   "source": [
    "#collect all app id's from steam \n",
    "data_ids = getAppList()\n",
    "\n",
    "#Code to collect all app id's in one list and write to a json file called app_ids \n",
    "all_app_ids = []\n",
    "print(\"Creating a list of all IDs currently available on Steam\")\n",
    "\n",
    "for item in data_ids['applist']['apps']:\n",
    "    all_app_ids.append(item['appid'])\n",
    "\n",
    "f = open('..\\\\..\\\\data\\\\app_ids.json','w',encoding='utf-8')\n",
    "f.write(json.dumps(all_app_ids)+'\\n')\n",
    "f.close()\n",
    "\n",
    "print(\"List created sucessfully, the total number of IDs available on Steam is:\", len(all_app_ids),\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code can be run to collect the appids, in case there was data collected earlier in the raw_data.json file than it will add to existing files. \n",
    "counter = 0\n",
    "limit = 10\n",
    "keys = ['categories','package_groups','genres','screenshots','movies', 'achievements.highlighted']\n",
    "Allkeys = ['ids', 'raw', 'categories','package_groups','genres','screenshots','movies', 'achievements.highlighted']\n",
    "dataframes = {}\n",
    "\n",
    "\n",
    "##creates dataframes for the seperate parsing keys \n",
    "for k in Allkeys:\n",
    "    file = f\"dataframe_{k}.xlsx\"\n",
    "    try:\n",
    "        dataframes[k] = pd.read_excel(file)\n",
    "    except:\n",
    "        print(f\"File doesn't exist {file}\")\n",
    "        dataframes[k] = pd.DataFrame()\n",
    "        pass\n",
    "\n",
    "\n",
    "## collect app_ids from the  app_ids file created before \n",
    "r = open('..\\\\..\\\\data\\\\app_ids.json','r',encoding='utf-8')\n",
    "app_ids = json.load(r)\n",
    "\n",
    "## creates an empty raw_data.json that can be appended on\n",
    "f = open('..\\\\..\\\\data\\\\raw_data.json','a',encoding='utf-8')\n",
    "\n",
    "# check if the json from earlier was created and set limit \n",
    "raw_exists = exists(\"..\\\\..\\\\data\\\\raw_data.json\")\n",
    "\n",
    "#create list of already collected id's \n",
    "if (raw_exists):\n",
    "    #create list of collected id's \n",
    "    col_ids = []\n",
    "    with open('..\\\\..\\\\data\\\\raw_data.json') as f: \n",
    "        for jsonObj in f: \n",
    "            rawDict = json.loads(jsonObj)\n",
    "            col_ids.append(rawDict[\"steam_appid\"])\n",
    "\n",
    "## getting the new data\n",
    "for i in app_ids: \n",
    "    if i not in col_ids:\n",
    "        if(counter > limit):\n",
    "            break\n",
    "        id = str(i)\n",
    "        counter = counter + 1\n",
    "        app_data = getAppDetails(i)\n",
    "        print(\"Processing data pertaining to Steam ID:\"+id)\n",
    "        if(app_data):\n",
    "            print(f\"Parsing id {i} with success\")\n",
    "            steam_appid = str(i)\n",
    "            result = pd.json_normalize(app_data)\n",
    "            dataframes['raw'] = pd.concat([dataframes['raw'], result])\n",
    "            dataframes['ids'] = pd.concat([dataframes['ids'], pd.json_normalize({'id' : i})])\n",
    "\n",
    "            for key in keys:\n",
    "                if( key not in dataframes):\n",
    "                    dataframes[key] = pd.DataFrame()\n",
    "                try:\n",
    "                    print(f\"Parsing id {i} for key {key}\")\n",
    "                    data = pd.json_normalize(app_data,record_path = [key], meta = [\"steam_appid\"], errors=\"ignore\")\n",
    "                    dataframes[key] = pd.concat([dataframes[key],data])            \n",
    "                    print(key)\n",
    "                except:\n",
    "                    pass                  \n",
    "    else:\n",
    "        print(f\"Skipping id {str(i)}\")\n",
    "        \n",
    "#writing the new data to the .xlsx files from the new dataframes\n",
    "for key in Allkeys:\n",
    "    print(f\"Writing to dataframe {key}\")\n",
    "    file = f\"..\\\\..\\\\data\\\\dataframe_{key}.xlsx\"\n",
    "    print(dataframes[key])\n",
    "    dataframes[key].to_excel(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[612440,\n",
       " 612470,\n",
       " 612491,\n",
       " 612500,\n",
       " 612510,\n",
       " 612520,\n",
       " 612540,\n",
       " 612570,\n",
       " 612580,\n",
       " 612590,\n",
       " 612600,\n",
       " 612610,\n",
       " 612620,\n",
       " 612640,\n",
       " 612650,\n",
       " 612660,\n",
       " 612670,\n",
       " 612720,\n",
       " 612730,\n",
       " 612740,\n",
       " 612750,\n",
       " 612790,\n",
       " 612810,\n",
       " 612820,\n",
       " 612830,\n",
       " 612840,\n",
       " 612850,\n",
       " 612870,\n",
       " 612880,\n",
       " 612890,\n",
       " 612900,\n",
       " 611960,\n",
       " 611970,\n",
       " 611980,\n",
       " 612000,\n",
       " 612010,\n",
       " 612020,\n",
       " 612030,\n",
       " 612040,\n",
       " 612050,\n",
       " 612060,\n",
       " 612070,\n",
       " 612100,\n",
       " 612110,\n",
       " 612120,\n",
       " 612130,\n",
       " 612140,\n",
       " 612150,\n",
       " 612160,\n",
       " 612170,\n",
       " 612180,\n",
       " 612190,\n",
       " 612200,\n",
       " 612210,\n",
       " 612220,\n",
       " 612230,\n",
       " 612240,\n",
       " 612250,\n",
       " 612260,\n",
       " 612261,\n",
       " 612280,\n",
       " 612300,\n",
       " 612310,\n",
       " 612330,\n",
       " 612370,\n",
       " 612380,\n",
       " 612390,\n",
       " 612400,\n",
       " 612420,\n",
       " 611620,\n",
       " 611630,\n",
       " 611640,\n",
       " 611650,\n",
       " 611660,\n",
       " 611670,\n",
       " 611690,\n",
       " 611710,\n",
       " 611720,\n",
       " 611730,\n",
       " 611740,\n",
       " 611750,\n",
       " 611760,\n",
       " 611770,\n",
       " 611790,\n",
       " 611800,\n",
       " 611810,\n",
       " 611820,\n",
       " 611830,\n",
       " 611850,\n",
       " 611860,\n",
       " 611890,\n",
       " 611950,\n",
       " 611490,\n",
       " 611491,\n",
       " 611492,\n",
       " 611493,\n",
       " 611494,\n",
       " 611495,\n",
       " 611496,\n",
       " 611497,\n",
       " 611498,\n",
       " 611500,\n",
       " 611510,\n",
       " 611511,\n",
       " 611512,\n",
       " 611513,\n",
       " 611514,\n",
       " 611520,\n",
       " 611521,\n",
       " 611522,\n",
       " 611523,\n",
       " 611524,\n",
       " 611525,\n",
       " 611526,\n",
       " 611527,\n",
       " 611528,\n",
       " 611540,\n",
       " 611541,\n",
       " 611542,\n",
       " 611543,\n",
       " 611544,\n",
       " 611545,\n",
       " 611546,\n",
       " 611547,\n",
       " 611548,\n",
       " 611549,\n",
       " 611550,\n",
       " 611220,\n",
       " 611230,\n",
       " 611250,\n",
       " 611260,\n",
       " 611270,\n",
       " 611300,\n",
       " 611310,\n",
       " 611320,\n",
       " 611350,\n",
       " 611360,\n",
       " 611370,\n",
       " 611390,\n",
       " 611400,\n",
       " 611420,\n",
       " 611421,\n",
       " 611430,\n",
       " 611431,\n",
       " 611432,\n",
       " 611440,\n",
       " 611441,\n",
       " 611442,\n",
       " 611443,\n",
       " 611444,\n",
       " 611445,\n",
       " 611446,\n",
       " 611447,\n",
       " 611448,\n",
       " 611449,\n",
       " 611450,\n",
       " 611451,\n",
       " 611452,\n",
       " 611460,\n",
       " 611470,\n",
       " 611480,\n",
       " 611481,\n",
       " 611482,\n",
       " 611483,\n",
       " 611484,\n",
       " 611485,\n",
       " 611486,\n",
       " 611487,\n",
       " 611488,\n",
       " 611489,\n",
       " 610740,\n",
       " 610750,\n",
       " 610760,\n",
       " 610780,\n",
       " 610790,\n",
       " 610810,\n",
       " 610820,\n",
       " 610830,\n",
       " 610840,\n",
       " 610850,\n",
       " 610860,\n",
       " 610870,\n",
       " 610900,\n",
       " 610910,\n",
       " 610940,\n",
       " 610960,\n",
       " 610970,\n",
       " 610980,\n",
       " 610990,\n",
       " 611020,\n",
       " 611040,\n",
       " 611050,\n",
       " 611060,\n",
       " 611080,\n",
       " 611090,\n",
       " 611110,\n",
       " 611120,\n",
       " 611140,\n",
       " 611160,\n",
       " 611170,\n",
       " 611180,\n",
       " 611190,\n",
       " 611200,\n",
       " 611210,\n",
       " 610460,\n",
       " 610470,\n",
       " 610480,\n",
       " 610500,\n",
       " 610510,\n",
       " 610520,\n",
       " 610530,\n",
       " 610550,\n",
       " 610560,\n",
       " 610570,\n",
       " 610610,\n",
       " 610620,\n",
       " 610630,\n",
       " 610640,\n",
       " 610650,\n",
       " 610660,\n",
       " 610670,\n",
       " 610680,\n",
       " 610690,\n",
       " 610691,\n",
       " 610692,\n",
       " 610693,\n",
       " 610694,\n",
       " 610695,\n",
       " 610696,\n",
       " 610697,\n",
       " 610698,\n",
       " 610699,\n",
       " 610700,\n",
       " 610701,\n",
       " 610702,\n",
       " 610704,\n",
       " 610705,\n",
       " 610706,\n",
       " 610708,\n",
       " 610709,\n",
       " 610720,\n",
       " 610730,\n",
       " 610010,\n",
       " 610040,\n",
       " 610050,\n",
       " 610070,\n",
       " 610080,\n",
       " 610090,\n",
       " 610100,\n",
       " 610110,\n",
       " 610120,\n",
       " 610130,\n",
       " 610150,\n",
       " 610160,\n",
       " 610180,\n",
       " 610190,\n",
       " 610210,\n",
       " 610220,\n",
       " 610221,\n",
       " 610222,\n",
       " 610250,\n",
       " 610260,\n",
       " 610270,\n",
       " 610280,\n",
       " 610290,\n",
       " 610310,\n",
       " 610330,\n",
       " 610340,\n",
       " 610350,\n",
       " 610360,\n",
       " 610370,\n",
       " 610380,\n",
       " 610400,\n",
       " 610410,\n",
       " 610420,\n",
       " 609720,\n",
       " 609730,\n",
       " 609760,\n",
       " 609770,\n",
       " 609800,\n",
       " 609820,\n",
       " 609821,\n",
       " 609822,\n",
       " 609823,\n",
       " 609824,\n",
       " 609825,\n",
       " 609826,\n",
       " 609827,\n",
       " 609828,\n",
       " 609829,\n",
       " 609830,\n",
       " 609850,\n",
       " 609880,\n",
       " 609920,\n",
       " 609940,\n",
       " 609970,\n",
       " 609980,\n",
       " 609700]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9f09fca4d15fa97f677e5901aabca61025ff22d892dc5a2f518eede0694e829"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

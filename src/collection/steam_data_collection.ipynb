{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries needed for this proces\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import numpy\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this block creates functions that can be used to extract the data from the steam API\n",
    "##maybe we can add this block in the source file as a functions file\n",
    "\n",
    "def get_request(url, parameters=None):\n",
    "    #function to create an API request based on URL and  parameters\n",
    "    print(\"Your request is being processed.\")\n",
    "    response = requests.get(url=url, params=parameters)\n",
    "    if response:\n",
    "        return response.json()\n",
    "        \n",
    "    else:\n",
    "        print(\"Request unsuccessful, retrying in 5 seconds.\")\n",
    "        time.sleep(5)\n",
    "        return get_request(url, parameters)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "def getAppList():\n",
    "    #using the function to get all data id's which include appid and app name \n",
    "    url = \"https://api.steampowered.com/ISteamApps/GetAppList/v2/\"\n",
    "    parameters = {\"request\": all}\n",
    "    return get_request(url, parameters=parameters)\n",
    "    print(\"Your request has been processed successfully, call upon 'data_ids' to preview the full list of IDs and names of all currently available products on Steam as of \", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"), \".\")\n",
    "    \n",
    "\n",
    "def getAppDetails(id):\n",
    "    #function to collect the raw data from the api per app_id\n",
    "    url = \"http://store.steampowered.com/api/appdetails/\"\n",
    "    parameters = {\"appids\": {id}}\n",
    "    raw_data = get_request(url, parameters=parameters)\n",
    "    response = raw_data[str(id)]\n",
    "    if(response['success']):\n",
    "        data_json = response[\"data\"]\n",
    "        data_json['collection_details'] = {'created_by': 'our_scraper',\n",
    "                                            'created_at': datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")}\n",
    "        f = open('raw_data.json','a',encoding='utf-8')\n",
    "        f.write(json.dumps(data_json)+'\\n')\n",
    "        f.close()\n",
    "        return data_json\n",
    "    return \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your request is being processed.\n",
      "Creating a list of all IDs currently available on Steam\n",
      "List created sucessfully, the total number of IDs available on Steam is: 138564 .\n"
     ]
    }
   ],
   "source": [
    "#collect all app id's from steam \n",
    "data_ids = getAppList()\n",
    "\n",
    "#Code to collect all app id's in one list and write to a json file called app_ids \n",
    "all_app_ids = []\n",
    "print(\"Creating a list of all IDs currently available on Steam\")\n",
    "\n",
    "for item in data_ids['applist']['apps']:\n",
    "    all_app_ids.append(item['appid'])\n",
    "\n",
    "f = open('app_ids.json','w',encoding='utf-8')\n",
    "f.write(json.dumps(all_app_ids)+'\\n')\n",
    "f.close()\n",
    "\n",
    "print(\"List created sucessfully, the total number of IDs available on Steam is:\", len(all_app_ids),\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the file that ultimatly creates the raw data file, and includes the parsing of the nested json categories\n",
    "counter = 0\n",
    "limit = 50\n",
    "keys = ['categories','package_groups','genres','screenshots','movies', 'achievements.highlighted']\n",
    "Allkeys = ['ids', 'raw', 'categories','package_groups','genres','screenshots','movies', 'achievements.highlighted']\n",
    "dataframes = {}\n",
    "\n",
    "## collect app_ids from the all app_ids file created before\n",
    "r = open('app_ids.json','r',encoding='utf-8')\n",
    "app_ids = json.load(r)\n",
    "\n",
    "\n",
    "##creates dataframes for the seperate parsing keys \n",
    "for k in Allkeys:\n",
    "    file = f\"dataframe_{k}.csv\"\n",
    "    try:\n",
    "        dataframes[k] = pd.read_csv(file)\n",
    "    except:\n",
    "        print(f\"File doesn't exist {file}\")\n",
    "        dataframes[k] = pd.DataFrame()\n",
    "        pass\n",
    "\n",
    "##collects data from the api and parses it in different dataframes with the name of the key\n",
    "for i in app_ids:\n",
    "    id = str(i)\n",
    "    \n",
    "    # if(not hasValueInDF(dataframes['ids'], 'id', i)): \n",
    "    if(True):\n",
    "        counter = counter + 1\n",
    "        if(counter > limit):\n",
    "            break\n",
    "        app_data = getAppDetails(i)\n",
    "        \n",
    "        print(\"Processing data pertaining to Steam ID:\"+id)\n",
    "            \n",
    "        if(app_data):\n",
    "            print(f\"Parsing id {i} with success\")\n",
    "            steam_appid = str(i)\n",
    "            result = pd.json_normalize(app_data)\n",
    "            dataframes['raw'] = pd.concat([dataframes['raw'], result])\n",
    "            dataframes['ids'] = pd.concat([dataframes['ids'], pd.json_normalize({'id' : i})])\n",
    "\n",
    "            for key in keys:\n",
    "                if( key not in dataframes):\n",
    "                    dataframes[key] = pd.DataFrame()\n",
    "                try:\n",
    "                    print(f\"Parsing id {i} for key {key}\")\n",
    "                    data = pd.json_normalize(app_data,record_path = [key], meta = [\"steam_appid\"], errors=\"ignore\")\n",
    "                    dataframes[key] = pd.concat([dataframes[key],data])            \n",
    "                    print(key)\n",
    "                except:\n",
    "                    pass\n",
    "    else:\n",
    "        print(f\"Skipping id {str(i)}\")\n",
    "\n",
    "\n",
    "##writes the dataframes to csv files based on the key  \n",
    "for key in Allkeys:\n",
    "    print(f\"Writing to dataframe {key}\")\n",
    "    file = f\"dataframe_{key}.csv\"\n",
    "    print(dataframes[key])\n",
    "    dataframes[key].to_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when a dataset was created earlier it is possible add App_ids to your dataset with the code below. \n",
    "\n",
    "## collect app_ids from the  app_ids file created before \n",
    "r = open('app_ids.json','r',encoding='utf-8')\n",
    "app_ids = json.load(r)\n",
    "\n",
    "# check if the json from earlier was created and set limit \n",
    "raw_exists = exists(\"raw_data.json\")\n",
    "counter = 0\n",
    "limit = 50\n",
    "\n",
    "#create list of already collected id's \n",
    "if (raw_exists):\n",
    "    #create list of collected id's \n",
    "    col_ids = []\n",
    "    with open('raw_data.json') as f: \n",
    "        for jsonObj in f: \n",
    "            rawDict = json.loads(jsonObj)\n",
    "            col_ids.append(rawDict[\"steam_appid\"])\n",
    "\n",
    "## getting the new data\n",
    "for i in app_ids: \n",
    "    if i not in col_ids:\n",
    "        if(counter > limit):\n",
    "            break\n",
    "        id = str(i)\n",
    "        counter = counter + 1\n",
    "        app_data = getAppDetails(i)\n",
    "        print(\"Processing data pertaining to Steam ID:\"+id)\n",
    "        if(app_data):\n",
    "            print(f\"Parsing id {i} with success\")\n",
    "            steam_appid = str(i)\n",
    "            result = pd.json_normalize(app_data)\n",
    "            dataframes['raw'] = pd.concat([dataframes['raw'], result])\n",
    "            dataframes['ids'] = pd.concat([dataframes['ids'], pd.json_normalize({'id' : i})])\n",
    "\n",
    "            for key in keys:\n",
    "                if( key not in dataframes):\n",
    "                    dataframes[key] = pd.DataFrame()\n",
    "                try:\n",
    "                    print(f\"Parsing id {i} for key {key}\")\n",
    "                    data = pd.json_normalize(app_data,record_path = [key], meta = [\"steam_appid\"], errors=\"ignore\")\n",
    "                    dataframes[key] = pd.concat([dataframes[key],data])            \n",
    "                    print(key)\n",
    "                except:\n",
    "                    pass   \n",
    "    else:\n",
    "        print(f\"Skipping id {str(i)}\")\n",
    "        \n",
    "\n",
    "for key in Allkeys:\n",
    "    print(f\"Writing to dataframe {key}\")\n",
    "    file = f\"dataframe_{key}.csv\"\n",
    "    print(dataframes[key])\n",
    "    dataframes[key].to_csv(file)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9f09fca4d15fa97f677e5901aabca61025ff22d892dc5a2f518eede0694e829"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
